{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to DataFrames\n",
    "**[Bogumił Kamiński](http://bogumilkaminski.pl/about/), May 26, 2020**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [>                                        ]  0.0 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [========>                                ]  20.0 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [================>                        ]  40.0 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [========================>                ]  60.0 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [================================>        ]  80.0 %\r",
      "    \u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [========================================>]  100.0 %\r",
      "\u001b[2K\u001b[?25h"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Project.toml`\n",
      " \u001b[90m [9e88b42a]\u001b[39m\u001b[92m + Serialization \u001b[39m\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Syslogs ─ v0.3.0\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m JLSO ──── v2.3.2\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Memento ─ v1.1.0\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Project.toml`\n",
      " \u001b[90m [9da8a3cd]\u001b[39m\u001b[92m + JLSO v2.3.2\u001b[39m\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Manifest.toml`\n",
      " \u001b[90m [9da8a3cd]\u001b[39m\u001b[92m + JLSO v2.3.2\u001b[39m\n",
      " \u001b[90m [f28f55f0]\u001b[39m\u001b[92m + Memento v1.1.0\u001b[39m\n",
      " \u001b[90m [cea106d9]\u001b[39m\u001b[92m + Syslogs v0.3.0\u001b[39m\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Arrow ─────── v0.2.4\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m FlatBuffers ─ v0.5.4\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Feather ───── v0.5.6\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Project.toml`\n",
      " \u001b[90m [becb17da]\u001b[39m\u001b[92m + Feather v0.5.6\u001b[39m\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Manifest.toml`\n",
      " \u001b[90m [69666777]\u001b[39m\u001b[92m + Arrow v0.2.4\u001b[39m\n",
      " \u001b[90m [becb17da]\u001b[39m\u001b[92m + Feather v0.5.6\u001b[39m\n",
      " \u001b[90m [53afe959]\u001b[39m\u001b[92m + FlatBuffers v0.5.4\u001b[39m\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Project.toml`\n",
      " \u001b[90m [944b1d66]\u001b[39m\u001b[92m + CodecZlib v0.6.0\u001b[39m\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Blosc_jll ─────── v1.14.3+1\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m BufferedStreams ─ v1.0.0\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Lz4_jll ───────── v1.9.2+2\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m Blosc ─────────── v0.7.0\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m JDF ───────────── v0.2.17\n",
      "######################################################################### 100.0%\n",
      "################################################################           88.6%######################################### 100.0%\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Project.toml`\n",
      " \u001b[90m [babc3d20]\u001b[39m\u001b[92m + JDF v0.2.17\u001b[39m\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Manifest.toml`\n",
      " \u001b[90m [a74b3585]\u001b[39m\u001b[92m + Blosc v0.7.0\u001b[39m\n",
      " \u001b[90m [0b7ba130]\u001b[39m\u001b[92m + Blosc_jll v1.14.3+1\u001b[39m\n",
      " \u001b[90m [e1450e63]\u001b[39m\u001b[92m + BufferedStreams v1.0.0\u001b[39m\n",
      " \u001b[90m [babc3d20]\u001b[39m\u001b[92m + JDF v0.2.17\u001b[39m\n",
      " \u001b[90m [5ced341a]\u001b[39m\u001b[92m + Lz4_jll v1.9.2+2\u001b[39m\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Project.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n",
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.4/Manifest.toml`\n",
      "\u001b[90m [no changes]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# jalankan skrip berikut jika library belum pernah digunakan/diinstall\n",
    "using Pkg\n",
    "Pkg.add(\"CSVFiles\")\n",
    "Pkg.add(\"Serialization\")\n",
    "Pkg.add(\"JLSO\")\n",
    "Pkg.add(\"Feather\")\n",
    "Pkg.add(\"JSONTables\")\n",
    "Pkg.add(\"CodecZlib\")\n",
    "Pkg.add(\"ZipFile\")\n",
    "Pkg.add(\"JDF\")\n",
    "Pkg.add(\"StatsPlots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and save DataFrames\n",
    "We do not cover all features of the packages. Please refer to their documentation to learn them.\n",
    "\n",
    "Here we'll load `CSV` and `CSVFiles` to read and write CSV files and `Feather`, `JLSO`, and serialization, which allow us to work with a binary format and `JSONTables` for JSON interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using CSVFiles\n",
    "using Serialization\n",
    "using JLSO\n",
    "using Feather\n",
    "using JSONTables\n",
    "using CodecZlib\n",
    "using ZipFile\n",
    "using JDF\n",
    "using StatsPlots # for charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple `DataFrame` for testing purposes,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>A</th><th>B</th><th>C</th><th>D</th></tr><tr><th></th><th>Bool</th><th>Int64?</th><th>String?</th><th>Char?</th></tr></thead><tbody><p>3 rows × 4 columns</p><tr><th>1</th><td>1</td><td>1</td><td><em>missing</em></td><td>'a'</td></tr><tr><th>2</th><td>0</td><td>2</td><td>b</td><td><em>missing</em></td></tr><tr><th>3</th><td>1</td><td><em>missing</em></td><td>c</td><td>'c'</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& A & B & C & D\\\\\n",
       "\t\\hline\n",
       "\t& Bool & Int64? & String? & Char?\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & \\emph{missing} & 'a' \\\\\n",
       "\t2 & 0 & 2 & b & \\emph{missing} \\\\\n",
       "\t3 & 1 & \\emph{missing} & c & 'c' \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "3×4 DataFrame\n",
       "│ Row │ A    │ B       │ C       │ D       │\n",
       "│     │ \u001b[90mBool\u001b[39m │ \u001b[90mInt64?\u001b[39m  │ \u001b[90mString?\u001b[39m │ \u001b[90mChar?\u001b[39m   │\n",
       "├─────┼──────┼─────────┼─────────┼─────────┤\n",
       "│ 1   │ 1    │ 1       │ \u001b[90mmissing\u001b[39m │ 'a'     │\n",
       "│ 2   │ 0    │ 2       │ b       │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 1    │ \u001b[90mmissing\u001b[39m │ c       │ 'c'     │"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = DataFrame(A=[true, false, true], B=[1, 2, missing],\n",
    "              C=[missing, \"b\", \"c\"], D=['a', missing, 'c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and use `eltypes` to look at the columnwise types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Type,1}:\n",
       " Bool\n",
       " Union{Missing, Int64}\n",
       " Union{Missing, String}\n",
       " Union{Missing, Char}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eltype.(eachcol(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `CSV` to save `x` to disk; make sure `x1.csv` does not conflict with some file in your working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"x1.csv\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV.write(\"x1.csv\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see how it was saved by reading `x.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C,D\n",
      "true,1,,a\n",
      "false,2,b,\n",
      "true,,c,c\n"
     ]
    }
   ],
   "source": [
    "print(read(\"x1.csv\", String))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load it back (`use_mmap=false` disables memory mapping so that on Windows the file can be deleted in the same session, on other OSs it is not needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>A</th><th>B</th><th>C</th><th>D</th></tr><tr><th></th><th>Bool</th><th>Int64?</th><th>String?</th><th>String?</th></tr></thead><tbody><p>3 rows × 4 columns</p><tr><th>1</th><td>1</td><td>1</td><td><em>missing</em></td><td>a</td></tr><tr><th>2</th><td>0</td><td>2</td><td>b</td><td><em>missing</em></td></tr><tr><th>3</th><td>1</td><td><em>missing</em></td><td>c</td><td>c</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& A & B & C & D\\\\\n",
       "\t\\hline\n",
       "\t& Bool & Int64? & String? & String?\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & \\emph{missing} & a \\\\\n",
       "\t2 & 0 & 2 & b & \\emph{missing} \\\\\n",
       "\t3 & 1 & \\emph{missing} & c & c \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "3×4 DataFrame\n",
       "│ Row │ A    │ B       │ C       │ D       │\n",
       "│     │ \u001b[90mBool\u001b[39m │ \u001b[90mInt64?\u001b[39m  │ \u001b[90mString?\u001b[39m │ \u001b[90mString?\u001b[39m │\n",
       "├─────┼──────┼─────────┼─────────┼─────────┤\n",
       "│ 1   │ 1    │ 1       │ \u001b[90mmissing\u001b[39m │ a       │\n",
       "│ 2   │ 0    │ 2       │ b       │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 1    │ \u001b[90mmissing\u001b[39m │ c       │ c       │"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = CSV.read(\"x1.csv\", use_mmap=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when loading in a `DataFrame` from a `CSV` the column type for column `:D` has changed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Type,1}:\n",
       " Bool\n",
       " Union{Missing, Int64}\n",
       " Union{Missing, String}\n",
       " Union{Missing, String}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eltype.(eachcol(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSVFiles.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use `CSVFiles` to achieve the same. First we save the file. Notice that we override default `nastring` that is `\"NA\"` because we have missings in non-numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x |> save(\"x2.csv\", nastring=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and peek the saved file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A\",\"B\",\"C\",\"D\"\n",
      "true,1,,a\n",
      "false,2,\"b\",\n",
      "true,,\"c\",c\n"
     ]
    }
   ],
   "source": [
    "print(read(\"x2.csv\", String))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load it back using `load`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>A</th><th>B</th><th>C</th><th>D</th></tr><tr><th></th><th>String</th><th>Int64?</th><th>String</th><th>String</th></tr></thead><tbody><p>3 rows × 4 columns</p><tr><th>1</th><td>true</td><td>1</td><td></td><td>a</td></tr><tr><th>2</th><td>false</td><td>2</td><td>b</td><td></td></tr><tr><th>3</th><td>true</td><td><em>missing</em></td><td>c</td><td>c</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& A & B & C & D\\\\\n",
       "\t\\hline\n",
       "\t& String & Int64? & String & String\\\\\n",
       "\t\\hline\n",
       "\t1 & true & 1 &  & a \\\\\n",
       "\t2 & false & 2 & b &  \\\\\n",
       "\t3 & true & \\emph{missing} & c & c \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "3×4 DataFrame\n",
       "│ Row │ A      │ B       │ C      │ D      │\n",
       "│     │ \u001b[90mString\u001b[39m │ \u001b[90mInt64?\u001b[39m  │ \u001b[90mString\u001b[39m │ \u001b[90mString\u001b[39m │\n",
       "├─────┼────────┼─────────┼────────┼────────┤\n",
       "│ 1   │ true   │ 1       │        │ a      │\n",
       "│ 2   │ false  │ 2       │ b      │        │\n",
       "│ 3   │ true   │ \u001b[90mmissing\u001b[39m │ c      │ c      │"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = load(\"x2.csv\") |> DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check element types again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Type,1}:\n",
       " String\n",
       " Union{Missing, Int64}\n",
       " String\n",
       " String"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eltype.(eachcol(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that in columns `:C` and `:D` missings were read back as empty strings. Also `Bool` got converted to `String`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialization, JDF.jl, and JLSO.jl\n",
    "\n",
    "#### Serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use serialization to save `x`.\n",
    "\n",
    "There are two ways to perform serialization. The first way is to use the `Serialization.serialize` as below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in general, this process will not work if the reading and writing are done by different versions of Julia, or an instance of Julia with a different system image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"x.bin\", \"w\") do io\n",
    "    serialize(io, x)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load back the saved file to `y` variable. Again `y` is identical to `x`. However, please beware that if you session does not have DataFrames.jl loaded, then it may not recognise the content as DataFrames.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>A</th><th>B</th><th>C</th><th>D</th></tr><tr><th></th><th>Bool</th><th>Int64?</th><th>String?</th><th>Char?</th></tr></thead><tbody><p>3 rows × 4 columns</p><tr><th>1</th><td>1</td><td>1</td><td><em>missing</em></td><td>'a'</td></tr><tr><th>2</th><td>0</td><td>2</td><td>b</td><td><em>missing</em></td></tr><tr><th>3</th><td>1</td><td><em>missing</em></td><td>c</td><td>'c'</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& A & B & C & D\\\\\n",
       "\t\\hline\n",
       "\t& Bool & Int64? & String? & Char?\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & \\emph{missing} & 'a' \\\\\n",
       "\t2 & 0 & 2 & b & \\emph{missing} \\\\\n",
       "\t3 & 1 & \\emph{missing} & c & 'c' \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "3×4 DataFrame\n",
       "│ Row │ A    │ B       │ C       │ D       │\n",
       "│     │ \u001b[90mBool\u001b[39m │ \u001b[90mInt64?\u001b[39m  │ \u001b[90mString?\u001b[39m │ \u001b[90mChar?\u001b[39m   │\n",
       "├─────┼──────┼─────────┼─────────┼─────────┤\n",
       "│ 1   │ 1    │ 1       │ \u001b[90mmissing\u001b[39m │ 'a'     │\n",
       "│ 2   │ 0    │ 2       │ b       │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 1    │ \u001b[90mmissing\u001b[39m │ c       │ 'c'     │"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = open(deserialize, \"x.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Type,1}:\n",
       " Bool\n",
       " Union{Missing, Int64}\n",
       " Union{Missing, String}\n",
       " Union{Missing, Char}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eltype.(eachcol(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JDF.jl\n",
    "\n",
    "[JDF.jl](https://github.com/xiaodaigh/JDF) is a relatively new package designed to serialize DataFrames. You can save a DataFrame with the `savejdf` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "savejdf(\"x.jdf\", x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the saved JDF file, one can use the `loadjdf` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>A</th><th>B</th><th>C</th><th>D</th></tr><tr><th></th><th>Bool</th><th>Int64?</th><th>String?</th><th>Char?</th></tr></thead><tbody><p>3 rows × 4 columns</p><tr><th>1</th><td>1</td><td>1</td><td><em>missing</em></td><td>'a'</td></tr><tr><th>2</th><td>0</td><td>2</td><td>b</td><td><em>missing</em></td></tr><tr><th>3</th><td>1</td><td><em>missing</em></td><td>c</td><td>'c'</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& A & B & C & D\\\\\n",
       "\t\\hline\n",
       "\t& Bool & Int64? & String? & Char?\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & \\emph{missing} & 'a' \\\\\n",
       "\t2 & 0 & 2 & b & \\emph{missing} \\\\\n",
       "\t3 & 1 & \\emph{missing} & c & 'c' \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "3×4 DataFrame\n",
       "│ Row │ A    │ B       │ C       │ D       │\n",
       "│     │ \u001b[90mBool\u001b[39m │ \u001b[90mInt64?\u001b[39m  │ \u001b[90mString?\u001b[39m │ \u001b[90mChar?\u001b[39m   │\n",
       "├─────┼──────┼─────────┼─────────┼─────────┤\n",
       "│ 1   │ 1    │ 1       │ \u001b[90mmissing\u001b[39m │ 'a'     │\n",
       "│ 2   │ 0    │ 2       │ b       │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 1    │ \u001b[90mmissing\u001b[39m │ c       │ 'c'     │"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_loaded = loadjdf(\"x.jdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that they are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isequal(x_loaded, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JDF.jl offers the ability to load only certain columns from disk to help with working with large files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JDFFile{String}(\"x.jdf\")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up a JDFFile which is a on disk representation of `x` backed by JDF.jl\n",
    "x_ondisk = jdf\"x.jdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see all the names of `x` without loading it into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{String,1}:\n",
       " \"A\"\n",
       " \"B\"\n",
       " \"C\"\n",
       " \"D\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names(x_ondisk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below is an example of how to load only columns `:A` and `:D` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>A</th><th>D</th></tr><tr><th></th><th>Bool</th><th>Char?</th></tr></thead><tbody><p>3 rows × 2 columns</p><tr><th>1</th><td>1</td><td>'a'</td></tr><tr><th>2</th><td>0</td><td><em>missing</em></td></tr><tr><th>3</th><td>1</td><td>'c'</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& A & D\\\\\n",
       "\t\\hline\n",
       "\t& Bool & Char?\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 'a' \\\\\n",
       "\t2 & 0 & \\emph{missing} \\\\\n",
       "\t3 & 1 & 'c' \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "3×2 DataFrame\n",
       "│ Row │ A    │ D       │\n",
       "│     │ \u001b[90mBool\u001b[39m │ \u001b[90mChar?\u001b[39m   │\n",
       "├─────┼──────┼─────────┤\n",
       "│ 1   │ 1    │ 'a'     │\n",
       "│ 2   │ 0    │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 1    │ 'c'     │"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xd = sloadjdf(x_ondisk; cols = [\"A\", \"D\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### JDF.jl vs others\n",
    "\n",
    "JDF.jl is specialized to DataFrames and only supports a restricted list of columns, so it can not save DataFrames with arbitrary column types. However, this also means that JDF.jl has specialised algorithms to serailize the type it supports to optimize speed, minimize disk usage, and reduce the chance of errors\n",
    "\n",
    "The list support columns for JDF include\n",
    "\n",
    "```julia\n",
    "WeakRefStrings.StringVector\n",
    "Vector{T}, Vector{Union{Mising, T}}, Vector{Union{Nothing, T}}\n",
    "CategoricalArrays.CategoricalVetors{T}\n",
    "```\n",
    "\n",
    "where `T` can be `String`, `Bool`, `Symbol`, `Char`, `TimeZones.ZonedDateTime` (experimental) and `isbit`s types i.e. `UInt*`, `Int*`, `Float*`, and `Date*` types etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JLSO.jl\n",
    "\n",
    "Another way to perform serialization is by using the [JLSO.jl](https://github.com/invenia/JLSO.jl) library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "JLSO.save(\"x.jlso\", :data => x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can laod back the file to `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>A</th><th>B</th><th>C</th><th>D</th></tr><tr><th></th><th>Bool</th><th>Int64?</th><th>String?</th><th>Char?</th></tr></thead><tbody><p>3 rows × 4 columns</p><tr><th>1</th><td>1</td><td>1</td><td><em>missing</em></td><td>'a'</td></tr><tr><th>2</th><td>0</td><td>2</td><td>b</td><td><em>missing</em></td></tr><tr><th>3</th><td>1</td><td><em>missing</em></td><td>c</td><td>'c'</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& A & B & C & D\\\\\n",
       "\t\\hline\n",
       "\t& Bool & Int64? & String? & Char?\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & \\emph{missing} & 'a' \\\\\n",
       "\t2 & 0 & 2 & b & \\emph{missing} \\\\\n",
       "\t3 & 1 & \\emph{missing} & c & 'c' \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "3×4 DataFrame\n",
       "│ Row │ A    │ B       │ C       │ D       │\n",
       "│     │ \u001b[90mBool\u001b[39m │ \u001b[90mInt64?\u001b[39m  │ \u001b[90mString?\u001b[39m │ \u001b[90mChar?\u001b[39m   │\n",
       "├─────┼──────┼─────────┼─────────┼─────────┤\n",
       "│ 1   │ 1    │ 1       │ \u001b[90mmissing\u001b[39m │ 'a'     │\n",
       "│ 2   │ 0    │ 2       │ b       │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 1    │ \u001b[90mmissing\u001b[39m │ c       │ 'c'     │"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = JLSO.load(\"x.jlso\")[:data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Type,1}:\n",
       " Bool\n",
       " Union{Missing, Int64}\n",
       " Union{Missing, String}\n",
       " Union{Missing, Char}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eltype.(eachcol(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSONTables.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often you might need to read and write data stored in JSON format. JSONTables.jl provides a way to process them in row-oriented or column-oriented layout. We present both options below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(io -> arraytable(io, x), \"x1.json\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(io -> objecttable(io, x), \"x2.json\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"A\":true,\"B\":1,\"C\":null,\"D\":\"a\"},{\"A\":false,\"B\":2,\"C\":\"b\",\"D\":null},{\"A\":true,\"B\":null,\"C\":\"c\",\"D\":\"c\"}]"
     ]
    }
   ],
   "source": [
    "print(read(\"x1.json\", String))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"A\":[true,false,true],\"B\":[1,2,null],\"C\":[null,\"b\",\"c\"],\"D\":[\"a\",null,\"c\"]}"
     ]
    }
   ],
   "source": [
    "print(read(\"x2.json\", String))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>A</th><th>B</th><th>C</th><th>D</th></tr><tr><th></th><th>Bool</th><th>Int64?</th><th>String?</th><th>String?</th></tr></thead><tbody><p>3 rows × 4 columns</p><tr><th>1</th><td>1</td><td>1</td><td><em>missing</em></td><td>a</td></tr><tr><th>2</th><td>0</td><td>2</td><td>b</td><td><em>missing</em></td></tr><tr><th>3</th><td>1</td><td><em>missing</em></td><td>c</td><td>c</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& A & B & C & D\\\\\n",
       "\t\\hline\n",
       "\t& Bool & Int64? & String? & String?\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & \\emph{missing} & a \\\\\n",
       "\t2 & 0 & 2 & b & \\emph{missing} \\\\\n",
       "\t3 & 1 & \\emph{missing} & c & c \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "3×4 DataFrame\n",
       "│ Row │ A    │ B       │ C       │ D       │\n",
       "│     │ \u001b[90mBool\u001b[39m │ \u001b[90mInt64?\u001b[39m  │ \u001b[90mString?\u001b[39m │ \u001b[90mString?\u001b[39m │\n",
       "├─────┼──────┼─────────┼─────────┼─────────┤\n",
       "│ 1   │ 1    │ 1       │ \u001b[90mmissing\u001b[39m │ a       │\n",
       "│ 2   │ 0    │ 2       │ b       │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 1    │ \u001b[90mmissing\u001b[39m │ c       │ c       │"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = open(jsontable, \"x1.json\") |> DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Type,1}:\n",
       " Bool\n",
       " Union{Missing, Int64}\n",
       " Union{Missing, String}\n",
       " Union{Missing, String}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eltype.(eachcol(y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>A</th><th>B</th><th>C</th><th>D</th></tr><tr><th></th><th>Bool</th><th>Int64?</th><th>String?</th><th>String?</th></tr></thead><tbody><p>3 rows × 4 columns</p><tr><th>1</th><td>1</td><td>1</td><td><em>missing</em></td><td>a</td></tr><tr><th>2</th><td>0</td><td>2</td><td>b</td><td><em>missing</em></td></tr><tr><th>3</th><td>1</td><td><em>missing</em></td><td>c</td><td>c</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& A & B & C & D\\\\\n",
       "\t\\hline\n",
       "\t& Bool & Int64? & String? & String?\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & \\emph{missing} & a \\\\\n",
       "\t2 & 0 & 2 & b & \\emph{missing} \\\\\n",
       "\t3 & 1 & \\emph{missing} & c & c \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "3×4 DataFrame\n",
       "│ Row │ A    │ B       │ C       │ D       │\n",
       "│     │ \u001b[90mBool\u001b[39m │ \u001b[90mInt64?\u001b[39m  │ \u001b[90mString?\u001b[39m │ \u001b[90mString?\u001b[39m │\n",
       "├─────┼──────┼─────────┼─────────┼─────────┤\n",
       "│ 1   │ 1    │ 1       │ \u001b[90mmissing\u001b[39m │ a       │\n",
       "│ 2   │ 0    │ 2       │ b       │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 1    │ \u001b[90mmissing\u001b[39m │ c       │ c       │"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = open(jsontable, \"x2.json\") |> DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Type,1}:\n",
       " Bool\n",
       " Union{Missing, Int64}\n",
       " Union{Missing, String}\n",
       " Union{Missing, String}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eltype.(eachcol(y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feather.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we use Feather format that allows, in particular, for data interchange with R or Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Union{Missing, String},1}:\n",
       " \"a\"\n",
       " missing\n",
       " \"c\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.D = passmissing(string).(x.D) # Feather format does not support Char type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"x.feather\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Feather.write(\"x.feather\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>A</th><th>B</th><th>C</th><th>D</th></tr><tr><th></th><th>Bool</th><th>Int64?</th><th>String?</th><th>String?</th></tr></thead><tbody><p>3 rows × 4 columns</p><tr><th>1</th><td>1</td><td>1</td><td><em>missing</em></td><td>a</td></tr><tr><th>2</th><td>0</td><td>2</td><td>b</td><td><em>missing</em></td></tr><tr><th>3</th><td>1</td><td><em>missing</em></td><td>c</td><td>c</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& A & B & C & D\\\\\n",
       "\t\\hline\n",
       "\t& Bool & Int64? & String? & String?\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & \\emph{missing} & a \\\\\n",
       "\t2 & 0 & 2 & b & \\emph{missing} \\\\\n",
       "\t3 & 1 & \\emph{missing} & c & c \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "3×4 DataFrame\n",
       "│ Row │ A    │ B       │ C       │ D       │\n",
       "│     │ \u001b[90mBool\u001b[39m │ \u001b[90mInt64?\u001b[39m  │ \u001b[90mString?\u001b[39m │ \u001b[90mString?\u001b[39m │\n",
       "├─────┼──────┼─────────┼─────────┼─────────┤\n",
       "│ 1   │ 1    │ 1       │ \u001b[90mmissing\u001b[39m │ a       │\n",
       "│ 2   │ 0    │ 2       │ b       │ \u001b[90mmissing\u001b[39m │\n",
       "│ 3   │ 1    │ \u001b[90mmissing\u001b[39m │ c       │ c       │"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = Feather.materialize(\"x.feather\") # Feather.read is a lazy alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Type,1}:\n",
       " Bool\n",
       " Union{Missing, Int64}\n",
       " Union{Missing, String}\n",
       " Union{Missing, String}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eltype.(eachcol(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic bechmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create some files, so be careful that you don't already have these files in your working directory!\n",
    "\n",
    "In particular, we'll time how long it takes us to write a `DataFrame` with 10^3 rows and 10^5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First run\n",
      "CSV.jl\n",
      "  8.225849 seconds (152.06 M allocations: 2.331 GiB, 9.45% gc time)\n",
      "CSVFiles.jl\n",
      " 12.792522 seconds (6.18 M allocations: 373.478 MiB, 0.57% gc time)\n",
      "Serialization\n",
      "  1.280607 seconds (204.40 k allocations: 10.697 MiB)\n",
      "JDF.jl\n",
      "  0.463312 seconds (96.95 k allocations: 166.966 MiB, 4.41% gc time)\n",
      "JLSO.jl\n",
      "  8.829102 seconds (290.41 k allocations: 178.629 MiB, 0.15% gc time)\n",
      "Feather.jl\n",
      "  0.254691 seconds (499.97 k allocations: 49.573 MiB, 3.65% gc time)\n",
      "JSONTables.jl arraytable\n",
      "168.000230 seconds (1.15 G allocations: 222.627 GiB, 8.12% gc time)\n",
      "JSONTables.jl objecttable\n",
      "  1.813862 seconds (386.70 k allocations: 1.403 GiB, 2.00% gc time)\n",
      "Second run\n",
      "CSV.jl\n",
      "  7.677150 seconds (150.14 M allocations: 2.247 GiB, 4.06% gc time)\n",
      "CSVFiles.jl\n",
      "  6.865196 seconds (606.56 k allocations: 105.606 MiB)\n",
      "Serialization\n",
      "  1.189541 seconds (5.62 k allocations: 771.223 KiB)\n",
      "JDF.jl\n",
      "  0.432028 seconds (20.63 k allocations: 163.216 MiB, 11.94% gc time)\n",
      "JLSO.jl\n",
      "  8.699682 seconds (26.40 k allocations: 166.194 MiB)\n",
      "Feather.jl\n",
      "  0.119212 seconds (157.87 k allocations: 32.756 MiB)\n",
      "JSONTables.jl arraytable\n",
      "195.969771 seconds (1.15 G allocations: 222.591 GiB, 6.31% gc time)\n",
      "JSONTables.jl objecttable\n",
      "  1.357717 seconds (12.83 k allocations: 1.386 GiB, 2.09% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.358529052"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdf = DataFrame(rand(Bool, 10^5, 500))\n",
    "bigdf[!, 1] = Int.(bigdf[!, 1])\n",
    "bigdf[!, 2] = bigdf[!, 2] .+ 0.5\n",
    "bigdf[!, 3] = string.(bigdf[!, 3], \", as string\")\n",
    "println(\"First run\")\n",
    "println(\"CSV.jl\")\n",
    "csvwrite1 = @elapsed @time CSV.write(\"bigdf1.csv\", bigdf)\n",
    "println(\"CSVFiles.jl\")\n",
    "csvfileswrite1 = @elapsed @time bigdf |> save(\"bigdf2.csv\")\n",
    "println(\"Serialization\")\n",
    "serializewrite1 = @elapsed @time open(io -> serialize(io, bigdf), \"bigdf.bin\", \"w\")\n",
    "println(\"JDF.jl\")\n",
    "jdfwrite1 = @elapsed @time savejdf(\"bigdf.jdf\", bigdf)\n",
    "println(\"JLSO.jl\")\n",
    "jlsowrite1 = @elapsed @time JLSO.save(\"bigdf.jlso\", :data => bigdf)\n",
    "println(\"Feather.jl\")\n",
    "featherwrite1 = @elapsed @time Feather.write(\"bigdf.feather\", bigdf)\n",
    "println(\"JSONTables.jl arraytable\")\n",
    "jsontablesawrite1 = @elapsed @time open(io -> arraytable(io, bigdf), \"bigdf1.json\", \"w\")\n",
    "println(\"JSONTables.jl objecttable\")\n",
    "jsontablesowrite1 = @elapsed @time open(io -> objecttable(io, bigdf), \"bigdf2.json\", \"w\")\n",
    "println(\"Second run\")\n",
    "println(\"CSV.jl\")\n",
    "csvwrite2 = @elapsed @time CSV.write(\"bigdf1.csv\", bigdf)\n",
    "println(\"CSVFiles.jl\")\n",
    "csvfileswrite2 = @elapsed @time bigdf |> save(\"bigdf2.csv\")\n",
    "println(\"Serialization\")\n",
    "serializewrite2 = @elapsed @time open(io -> serialize(io, bigdf), \"bigdf.bin\", \"w\")\n",
    "println(\"JDF.jl\")\n",
    "jdfwrite2 = @elapsed @time savejdf(\"bigdf.jdf\", bigdf)\n",
    "println(\"JLSO.jl\")\n",
    "jlsowrite2 = @elapsed @time JLSO.save(\"bigdf.jlso\", :data => bigdf)\n",
    "println(\"Feather.jl\")\n",
    "featherwrite2 = @elapsed @time Feather.write(\"bigdf.feather\", bigdf)\n",
    "println(\"JSONTables.jl arraytable\")\n",
    "jsontablesawrite2 = @elapsed @time open(io -> arraytable(io, bigdf), \"bigdf1.json\", \"w\")\n",
    "println(\"JSONTables.jl objecttable\")\n",
    "jsontablesowrite2 = @elapsed @time open(io -> objecttable(io, bigdf), \"bigdf2.json\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: csvwrite1 not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: csvwrite1 not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[42]:1"
     ]
    }
   ],
   "source": [
    "groupedbar(\n",
    "    #repeat([\"CSV.jl\", \"CSVFiles.jl\", \"Serialization\", \"JDF.jl\", \"JLSO.jl\", \"Feather.jl\", \"JSONTables.jl\\narraytable\", \"JSONTables.jl\\nobjecttable\"], inner = 2),\n",
    "    #[csvwrite1, csvwrite2, csvfileswrite1, csvfileswrite2, serializewrite1, serializewrite1, jdfwrite1, jdfwrite2, jlsowrite1, jlsowrite2, featherwrite1, featherwrite2, jsontablesawrite1, jsontablesawrite2, jsontablesowrite2, jsontablesowrite2],\n",
    "    # Exclude JSONTables.jl arraytable due to timing\n",
    "    repeat([\"CSV.jl\", \"CSVFiles.jl\", \"Serialization\", \"JDF.jl\", \"JLSO.jl\", \"Feather.jl\", \"JSONTables.jl\\nobjecttable\"],\n",
    "            inner = 2),\n",
    "    [csvwrite1, csvwrite2, csvfileswrite1, csvfileswrite2, serializewrite1, serializewrite1, jdfwrite1, jdfwrite2,\n",
    "     jlsowrite1, jlsowrite2, featherwrite1, featherwrite2, jsontablesowrite2, jsontablesowrite2],\n",
    "    group = repeat([\"1st\", \"2nd\"], outer = 7),\n",
    "    ylab = \"Second\",\n",
    "    title = \"Write Performance\\nDataFrame: bigdf\\nSize: $(size(bigdf))\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "SystemError: unable to read directory bigdf.jdf: No such file or directory",
     "output_type": "error",
     "traceback": [
      "SystemError: unable to read directory bigdf.jdf: No such file or directory",
      "",
      "Stacktrace:",
      " [1] readdir(::String; join::Bool, sort::Bool) at ./file.jl:780",
      " [2] readdir(::String) at ./file.jl:775",
      " [3] top-level scope at In[43]:3"
     ]
    }
   ],
   "source": [
    "data_files = [\"bigdf1.csv\", \"bigdf2.csv\", \"bigdf.bin\", \"bigdf.feather\", \"bigdf1.json\", \"bigdf2.json\"]\n",
    "df = DataFrame(file = data_files, size = getfield.(stat.(data_files), :size))\n",
    "append!(df, DataFrame(file = \"bigdf.jdf\", size=reduce((x,y)->x+y.size,\n",
    "                                                      stat.(joinpath.(\"bigdf.jdf\", readdir(\"bigdf.jdf\"))),\n",
    "                                                      init=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "could not load library \"libGR.so\"\ndlopen(libGR.so.dylib, 1): image not found",
     "output_type": "error",
     "traceback": [
      "could not load library \"libGR.so\"\ndlopen(libGR.so.dylib, 1): image not found",
      "",
      "Stacktrace:",
      " [1] setcharheight at /Users/ujangfahmi/.julia/packages/GR/yMV3y/src/GR.jl:1273 [inlined]",
      " [2] gr_set_font(::Plots.Font; halign::Symbol, valign::Symbol, color::RGB{FixedPointNumbers.Normed{UInt8,8}}, rotation::Float64) at /Users/ujangfahmi/.julia/packages/Plots/cc8wh/src/backends/gr.jl:389",
      " [3] gr_set_font(::Plots.Font) at /Users/ujangfahmi/.julia/packages/Plots/cc8wh/src/backends/gr.jl:388",
      " [4] _update_min_padding!(::Plots.Subplot{Plots.GRBackend}) at /Users/ujangfahmi/.julia/packages/Plots/cc8wh/src/backends/gr.jl:830",
      " [5] iterate at ./generator.jl:47 [inlined]",
      " [6] _collect(::Array{AbstractLayout,2}, ::Base.Generator{Array{AbstractLayout,2},typeof(Plots._update_min_padding!)}, ::Base.EltypeUnknown, ::Base.HasShape{2}) at ./array.jl:678",
      " [7] collect_similar(::Array{AbstractLayout,2}, ::Base.Generator{Array{AbstractLayout,2},typeof(Plots._update_min_padding!)}) at ./array.jl:607",
      " [8] map(::Function, ::Array{AbstractLayout,2}) at ./abstractarray.jl:2072",
      " [9] _update_min_padding!(::Plots.GridLayout) at /Users/ujangfahmi/.julia/packages/Plots/cc8wh/src/layouts.jl:310",
      " [10] prepare_output(::Plots.Plot{Plots.GRBackend}) at /Users/ujangfahmi/.julia/packages/Plots/cc8wh/src/plot.jl:260",
      " [11] show(::Base.GenericIOBuffer{Array{UInt8,1}}, ::MIME{Symbol(\"image/svg+xml\")}, ::Plots.Plot{Plots.GRBackend}) at /Users/ujangfahmi/.julia/packages/Plots/cc8wh/src/output.jl:215",
      " [12] sprint(::Function, ::MIME{Symbol(\"image/svg+xml\")}, ::Vararg{Any,N} where N; context::Nothing, sizehint::Int64) at ./strings/io.jl:105",
      " [13] sprint at ./strings/io.jl:101 [inlined]",
      " [14] _ijulia_display_dict(::Plots.Plot{Plots.GRBackend}) at /Users/ujangfahmi/.julia/packages/Plots/cc8wh/src/ijulia.jl:53",
      " [15] display_dict(::Plots.Plot{Plots.GRBackend}) at /Users/ujangfahmi/.julia/packages/Plots/cc8wh/src/init.jl:83",
      " [16] #invokelatest#1 at ./essentials.jl:712 [inlined]",
      " [17] invokelatest at ./essentials.jl:711 [inlined]",
      " [18] execute_request(::ZMQ.Socket, ::IJulia.Msg) at /Users/ujangfahmi/.julia/packages/IJulia/DrVMH/src/execute_request.jl:112",
      " [19] #invokelatest#1 at ./essentials.jl:712 [inlined]",
      " [20] invokelatest at ./essentials.jl:711 [inlined]",
      " [21] eventloop(::ZMQ.Socket) at /Users/ujangfahmi/.julia/packages/IJulia/DrVMH/src/eventloop.jl:8",
      " [22] (::IJulia.var\"#15#18\")() at ./task.jl:358"
     ]
    }
   ],
   "source": [
    "@df df plot(:file, :size/1024^2, seriestype=:bar, title = \"Format File Size (MB)\", label=\"Size\", ylab=\"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First run\n",
      "CSV.jl\n"
     ]
    },
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: \"bigdf1.csv\" is not a valid file",
     "output_type": "error",
     "traceback": [
      "ArgumentError: \"bigdf1.csv\" is not a valid file",
      "",
      "Stacktrace:",
      " [1] CSV.Header(::String, ::Int64, ::Bool, ::Int64, ::Nothing, ::Int64, ::Int64, ::Bool, ::Nothing, ::Bool, ::Bool, ::Nothing, ::Nothing, ::Nothing, ::Array{String,1}, ::String, ::Nothing, ::Bool, ::Char, ::Nothing, ::Nothing, ::Char, ::Nothing, ::Nothing, ::UInt8, ::Array{String,1}, ::Array{String,1}, ::Nothing, ::Nothing, ::Dict{Int8,Int8}, ::Bool, ::Float64, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /Users/ujangfahmi/.julia/packages/CSV/vyG0T/src/header.jl:84",
      " [2] CSV.File(::String; header::Int64, normalizenames::Bool, datarow::Int64, skipto::Nothing, footerskip::Int64, limit::Int64, transpose::Bool, comment::Nothing, use_mmap::Bool, ignoreemptylines::Bool, threaded::Nothing, select::Nothing, drop::Nothing, missingstrings::Array{String,1}, missingstring::String, delim::Nothing, ignorerepeated::Bool, quotechar::Char, openquotechar::Nothing, closequotechar::Nothing, escapechar::Char, dateformat::Nothing, dateformats::Nothing, decimal::UInt8, truestrings::Array{String,1}, falsestrings::Array{String,1}, type::Nothing, types::Nothing, typemap::Dict{Int8,Int8}, categorical::Bool, pool::Float64, strict::Bool, silencewarnings::Bool, debug::Bool, parsingdebug::Bool) at /Users/ujangfahmi/.julia/packages/CSV/vyG0T/src/file.jl:210",
      " [3] CSV.File(::String) at /Users/ujangfahmi/.julia/packages/CSV/vyG0T/src/file.jl:210",
      " [4] #read#84 at /Users/ujangfahmi/.julia/packages/CSV/vyG0T/src/CSV.jl:41 [inlined]",
      " [5] read at /Users/ujangfahmi/.julia/packages/CSV/vyG0T/src/CSV.jl:41 [inlined]",
      " [6] macro expansion at ./util.jl:175 [inlined]",
      " [7] top-level scope at ./In[45]:3"
     ]
    }
   ],
   "source": [
    "println(\"First run\")\n",
    "println(\"CSV.jl\")\n",
    "csvread1 = @elapsed @time CSV.read(\"bigdf1.csv\")\n",
    "println(\"CSVFiles.jl\")\n",
    "println(\"  disabled due to time-out\")\n",
    "# @time load(\"bigdf2.csv\") |> DataFrame\n",
    "println(\"Serialization\")\n",
    "serializeread1 = @elapsed @time open(deserialize, \"bigdf.bin\")\n",
    "println(\"JDF.jl\")\n",
    "jdfread1 = @elapsed @time loadjdf(\"bigdf.jdf\")\n",
    "println(\"JLSO.jl\")\n",
    "jlsoread1 = @elapsed @time JLSO.load(\"bigdf.jlso\")\n",
    "println(\"Feather.jl\")\n",
    "featherread1 = @elapsed @time Feather.materialize(\"bigdf.feather\")\n",
    "println(\"JSONTables.jl arraytable\")\n",
    "jsontablesaread1 = @elapsed @time open(jsontable, \"bigdf1.json\")\n",
    "println(\"JSONTables.jl objecttable\")\n",
    "jsontablesoread1 = @elapsed @time open(jsontable, \"bigdf2.json\")\n",
    "println(\"Second run\")\n",
    "csvread2 = @elapsed @time CSV.read(\"bigdf1.csv\")\n",
    "println(\"CSVFiles.jl\")\n",
    "println(\"  disabled due to time-out\")\n",
    "# @time load(\"bigdf2.csv\") |> DataFrame\n",
    "println(\"Serialization\")\n",
    "serializeread2 = @elapsed @time open(deserialize, \"bigdf.bin\")\n",
    "println(\"JDF.jl\")\n",
    "jdfread2 = @elapsed @time loadjdf(\"bigdf.jdf\")\n",
    "println(\"JLSO.jl\")\n",
    "jlsoread2 = @elapsed @time JLSO.load(\"bigdf.jlso\")\n",
    "println(\"Feather.jl\")\n",
    "featherread2 = @elapsed @time Feather.materialize(\"bigdf.feather\")\n",
    "println(\"JSONTables.jl arraytable\")\n",
    "jsontablesaread2 = @elapsed @time open(jsontable, \"bigdf1.json\")\n",
    "println(\"JSONTables.jl objecttable\")\n",
    "jsontablesoread2 = @elapsed @time open(jsontable, \"bigdf2.json\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: csvread1 not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: csvread1 not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[46]:1"
     ]
    }
   ],
   "source": [
    "groupedbar(\n",
    "    repeat([\"CSV.jl\", \"Serialization\", \"JDF.jl\", \"JLSO.jl\", \"Feather.jl\", \"JSONTables.jl\\narraytable\",\n",
    "            \"JSONTables.jl\\nobjecttable\"], inner = 2),\n",
    "    [csvread1, csvread2, serializeread1, serializeread1, jdfread1, jdfread2, jlsoread1, jlsoread2,\n",
    "     featherread1, featherread2, jsontablesaread1, jsontablesaread2, jsontablesoread2, jsontablesoread2],    \n",
    "    group = repeat([\"1st\", \"2nd\"], outer = 7),\n",
    "    ylab = \"Second\",\n",
    "    title = \"Read Performance\\nDataFrame: bigdf\\nSize: $(size(bigdf))\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using gzip compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common user requirement is to be able to load and save CSV that are compressed using gzip.\n",
    "Below we show how this can be accomplished using CodecZlib.jl.\n",
    "The same pattern is applicable to JSONTables.jl compression/decompression.\n",
    "\n",
    "Again make sure that you do not have file named `df_compress_test.csv.gz` in your working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first generate a random data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>x1</th><th>x2</th><th>x3</th><th>x4</th><th>x5</th><th>x6</th><th>x7</th><th>x8</th><th>x9</th><th>x10</th><th>x11</th><th>x12</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>10 rows × 1,000 columns (omitted printing of 988 columns)</p><tr><th>1</th><td>1</td><td>4</td><td>2</td><td>10</td><td>10</td><td>2</td><td>6</td><td>8</td><td>9</td><td>2</td><td>3</td><td>4</td></tr><tr><th>2</th><td>1</td><td>9</td><td>1</td><td>3</td><td>8</td><td>3</td><td>3</td><td>3</td><td>7</td><td>5</td><td>4</td><td>1</td></tr><tr><th>3</th><td>8</td><td>8</td><td>8</td><td>2</td><td>9</td><td>3</td><td>2</td><td>5</td><td>10</td><td>8</td><td>8</td><td>10</td></tr><tr><th>4</th><td>6</td><td>2</td><td>4</td><td>1</td><td>8</td><td>9</td><td>2</td><td>3</td><td>7</td><td>4</td><td>10</td><td>9</td></tr><tr><th>5</th><td>6</td><td>6</td><td>5</td><td>8</td><td>10</td><td>9</td><td>4</td><td>1</td><td>4</td><td>2</td><td>10</td><td>8</td></tr><tr><th>6</th><td>3</td><td>3</td><td>9</td><td>8</td><td>2</td><td>10</td><td>10</td><td>9</td><td>4</td><td>8</td><td>3</td><td>6</td></tr><tr><th>7</th><td>2</td><td>7</td><td>1</td><td>4</td><td>7</td><td>10</td><td>10</td><td>3</td><td>1</td><td>1</td><td>7</td><td>4</td></tr><tr><th>8</th><td>3</td><td>8</td><td>8</td><td>9</td><td>1</td><td>8</td><td>7</td><td>4</td><td>5</td><td>4</td><td>1</td><td>4</td></tr><tr><th>9</th><td>5</td><td>7</td><td>6</td><td>7</td><td>1</td><td>2</td><td>4</td><td>1</td><td>2</td><td>1</td><td>1</td><td>5</td></tr><tr><th>10</th><td>2</td><td>9</td><td>3</td><td>1</td><td>2</td><td>9</td><td>1</td><td>5</td><td>5</td><td>8</td><td>9</td><td>9</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccccccc}\n",
       "\t& x1 & x2 & x3 & x4 & x5 & x6 & x7 & x8 & x9 & x10 & x11 & x12 & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 4 & 2 & 10 & 10 & 2 & 6 & 8 & 9 & 2 & 3 & 4 & $\\dots$ \\\\\n",
       "\t2 & 1 & 9 & 1 & 3 & 8 & 3 & 3 & 3 & 7 & 5 & 4 & 1 & $\\dots$ \\\\\n",
       "\t3 & 8 & 8 & 8 & 2 & 9 & 3 & 2 & 5 & 10 & 8 & 8 & 10 & $\\dots$ \\\\\n",
       "\t4 & 6 & 2 & 4 & 1 & 8 & 9 & 2 & 3 & 7 & 4 & 10 & 9 & $\\dots$ \\\\\n",
       "\t5 & 6 & 6 & 5 & 8 & 10 & 9 & 4 & 1 & 4 & 2 & 10 & 8 & $\\dots$ \\\\\n",
       "\t6 & 3 & 3 & 9 & 8 & 2 & 10 & 10 & 9 & 4 & 8 & 3 & 6 & $\\dots$ \\\\\n",
       "\t7 & 2 & 7 & 1 & 4 & 7 & 10 & 10 & 3 & 1 & 1 & 7 & 4 & $\\dots$ \\\\\n",
       "\t8 & 3 & 8 & 8 & 9 & 1 & 8 & 7 & 4 & 5 & 4 & 1 & 4 & $\\dots$ \\\\\n",
       "\t9 & 5 & 7 & 6 & 7 & 1 & 2 & 4 & 1 & 2 & 1 & 1 & 5 & $\\dots$ \\\\\n",
       "\t10 & 2 & 9 & 3 & 1 & 2 & 9 & 1 & 5 & 5 & 8 & 9 & 9 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×1000 DataFrame. Omitted printing of 991 columns\n",
       "│ Row │ x1    │ x2    │ x3    │ x4    │ x5    │ x6    │ x7    │ x8    │ x9    │\n",
       "│     │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │\n",
       "├─────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┤\n",
       "│ 1   │ 1     │ 4     │ 2     │ 10    │ 10    │ 2     │ 6     │ 8     │ 9     │\n",
       "│ 2   │ 1     │ 9     │ 1     │ 3     │ 8     │ 3     │ 3     │ 3     │ 7     │\n",
       "│ 3   │ 8     │ 8     │ 8     │ 2     │ 9     │ 3     │ 2     │ 5     │ 10    │\n",
       "│ 4   │ 6     │ 2     │ 4     │ 1     │ 8     │ 9     │ 2     │ 3     │ 7     │\n",
       "│ 5   │ 6     │ 6     │ 5     │ 8     │ 10    │ 9     │ 4     │ 1     │ 4     │\n",
       "│ 6   │ 3     │ 3     │ 9     │ 8     │ 2     │ 10    │ 10    │ 9     │ 4     │\n",
       "│ 7   │ 2     │ 7     │ 1     │ 4     │ 7     │ 10    │ 10    │ 3     │ 1     │\n",
       "│ 8   │ 3     │ 8     │ 8     │ 9     │ 1     │ 8     │ 7     │ 4     │ 5     │\n",
       "│ 9   │ 5     │ 7     │ 6     │ 7     │ 1     │ 2     │ 4     │ 1     │ 2     │\n",
       "│ 10  │ 2     │ 9     │ 3     │ 1     │ 2     │ 9     │ 1     │ 5     │ 5     │"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataFrame(rand(1:10, 10, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GzipCompressorStream comes from CodecZlib\n",
    "\n",
    "open(\"df_compress_test.csv.gz\", \"w\") do io\n",
    "    stream = GzipCompressorStream(io)\n",
    "    CSV.write(stream, df)\n",
    "    close(stream)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>x1</th><th>x2</th><th>x3</th><th>x4</th><th>x5</th><th>x6</th><th>x7</th><th>x8</th><th>x9</th><th>x10</th><th>x11</th><th>x12</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>10 rows × 1,000 columns (omitted printing of 988 columns)</p><tr><th>1</th><td>1</td><td>4</td><td>2</td><td>10</td><td>10</td><td>2</td><td>6</td><td>8</td><td>9</td><td>2</td><td>3</td><td>4</td></tr><tr><th>2</th><td>1</td><td>9</td><td>1</td><td>3</td><td>8</td><td>3</td><td>3</td><td>3</td><td>7</td><td>5</td><td>4</td><td>1</td></tr><tr><th>3</th><td>8</td><td>8</td><td>8</td><td>2</td><td>9</td><td>3</td><td>2</td><td>5</td><td>10</td><td>8</td><td>8</td><td>10</td></tr><tr><th>4</th><td>6</td><td>2</td><td>4</td><td>1</td><td>8</td><td>9</td><td>2</td><td>3</td><td>7</td><td>4</td><td>10</td><td>9</td></tr><tr><th>5</th><td>6</td><td>6</td><td>5</td><td>8</td><td>10</td><td>9</td><td>4</td><td>1</td><td>4</td><td>2</td><td>10</td><td>8</td></tr><tr><th>6</th><td>3</td><td>3</td><td>9</td><td>8</td><td>2</td><td>10</td><td>10</td><td>9</td><td>4</td><td>8</td><td>3</td><td>6</td></tr><tr><th>7</th><td>2</td><td>7</td><td>1</td><td>4</td><td>7</td><td>10</td><td>10</td><td>3</td><td>1</td><td>1</td><td>7</td><td>4</td></tr><tr><th>8</th><td>3</td><td>8</td><td>8</td><td>9</td><td>1</td><td>8</td><td>7</td><td>4</td><td>5</td><td>4</td><td>1</td><td>4</td></tr><tr><th>9</th><td>5</td><td>7</td><td>6</td><td>7</td><td>1</td><td>2</td><td>4</td><td>1</td><td>2</td><td>1</td><td>1</td><td>5</td></tr><tr><th>10</th><td>2</td><td>9</td><td>3</td><td>1</td><td>2</td><td>9</td><td>1</td><td>5</td><td>5</td><td>8</td><td>9</td><td>9</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccccccc}\n",
       "\t& x1 & x2 & x3 & x4 & x5 & x6 & x7 & x8 & x9 & x10 & x11 & x12 & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 4 & 2 & 10 & 10 & 2 & 6 & 8 & 9 & 2 & 3 & 4 & $\\dots$ \\\\\n",
       "\t2 & 1 & 9 & 1 & 3 & 8 & 3 & 3 & 3 & 7 & 5 & 4 & 1 & $\\dots$ \\\\\n",
       "\t3 & 8 & 8 & 8 & 2 & 9 & 3 & 2 & 5 & 10 & 8 & 8 & 10 & $\\dots$ \\\\\n",
       "\t4 & 6 & 2 & 4 & 1 & 8 & 9 & 2 & 3 & 7 & 4 & 10 & 9 & $\\dots$ \\\\\n",
       "\t5 & 6 & 6 & 5 & 8 & 10 & 9 & 4 & 1 & 4 & 2 & 10 & 8 & $\\dots$ \\\\\n",
       "\t6 & 3 & 3 & 9 & 8 & 2 & 10 & 10 & 9 & 4 & 8 & 3 & 6 & $\\dots$ \\\\\n",
       "\t7 & 2 & 7 & 1 & 4 & 7 & 10 & 10 & 3 & 1 & 1 & 7 & 4 & $\\dots$ \\\\\n",
       "\t8 & 3 & 8 & 8 & 9 & 1 & 8 & 7 & 4 & 5 & 4 & 1 & 4 & $\\dots$ \\\\\n",
       "\t9 & 5 & 7 & 6 & 7 & 1 & 2 & 4 & 1 & 2 & 1 & 1 & 5 & $\\dots$ \\\\\n",
       "\t10 & 2 & 9 & 3 & 1 & 2 & 9 & 1 & 5 & 5 & 8 & 9 & 9 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×1000 DataFrame. Omitted printing of 991 columns\n",
       "│ Row │ x1    │ x2    │ x3    │ x4    │ x5    │ x6    │ x7    │ x8    │ x9    │\n",
       "│     │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │\n",
       "├─────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┼───────┤\n",
       "│ 1   │ 1     │ 4     │ 2     │ 10    │ 10    │ 2     │ 6     │ 8     │ 9     │\n",
       "│ 2   │ 1     │ 9     │ 1     │ 3     │ 8     │ 3     │ 3     │ 3     │ 7     │\n",
       "│ 3   │ 8     │ 8     │ 8     │ 2     │ 9     │ 3     │ 2     │ 5     │ 10    │\n",
       "│ 4   │ 6     │ 2     │ 4     │ 1     │ 8     │ 9     │ 2     │ 3     │ 7     │\n",
       "│ 5   │ 6     │ 6     │ 5     │ 8     │ 10    │ 9     │ 4     │ 1     │ 4     │\n",
       "│ 6   │ 3     │ 3     │ 9     │ 8     │ 2     │ 10    │ 10    │ 9     │ 4     │\n",
       "│ 7   │ 2     │ 7     │ 1     │ 4     │ 7     │ 10    │ 10    │ 3     │ 1     │\n",
       "│ 8   │ 3     │ 8     │ 8     │ 9     │ 1     │ 8     │ 7     │ 4     │ 5     │\n",
       "│ 9   │ 5     │ 7     │ 6     │ 7     │ 1     │ 2     │ 4     │ 1     │ 2     │\n",
       "│ 10  │ 2     │ 9     │ 3     │ 1     │ 2     │ 9     │ 1     │ 5     │ 5     │"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = open(\"df_compress_test.csv.gz\") do io\n",
    "    stream = GzipDecompressorStream(io)\n",
    "    res = CSV.read(stream)\n",
    "    close(stream)\n",
    "    res\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df == df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using zip files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you may have files compressed inside a zip file.\n",
    "\n",
    "In such a situation you may use [ZipFile.jl](https://github.com/fhs/ZipFile.jl) in conjunction an an appropriate reader to read the files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we first create a ZIP file and then read back its contents into a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>x1</th><th>x2</th><th>x3</th><th>x4</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>3 rows × 4 columns</p><tr><th>1</th><td>5</td><td>5</td><td>7</td><td>10</td></tr><tr><th>2</th><td>8</td><td>8</td><td>10</td><td>10</td></tr><tr><th>3</th><td>1</td><td>7</td><td>5</td><td>10</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& x1 & x2 & x3 & x4\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 5 & 5 & 7 & 10 \\\\\n",
       "\t2 & 8 & 8 & 10 & 10 \\\\\n",
       "\t3 & 1 & 7 & 5 & 10 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "3×4 DataFrame\n",
       "│ Row │ x1    │ x2    │ x3    │ x4    │\n",
       "│     │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │\n",
       "├─────┼───────┼───────┼───────┼───────┤\n",
       "│ 1   │ 5     │ 5     │ 7     │ 10    │\n",
       "│ 2   │ 8     │ 8     │ 10    │ 10    │\n",
       "│ 3   │ 1     │ 7     │ 5     │ 10    │"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = DataFrame(rand(1:10, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>x1</th><th>x2</th><th>x3</th><th>x4</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>3 rows × 4 columns</p><tr><th>1</th><td>10</td><td>9</td><td>6</td><td>10</td></tr><tr><th>2</th><td>9</td><td>2</td><td>1</td><td>10</td></tr><tr><th>3</th><td>4</td><td>1</td><td>9</td><td>3</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& x1 & x2 & x3 & x4\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 10 & 9 & 6 & 10 \\\\\n",
       "\t2 & 9 & 2 & 1 & 10 \\\\\n",
       "\t3 & 4 & 1 & 9 & 3 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "3×4 DataFrame\n",
       "│ Row │ x1    │ x2    │ x3    │ x4    │\n",
       "│     │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │\n",
       "├─────┼───────┼───────┼───────┼───────┤\n",
       "│ 1   │ 10    │ 9     │ 6     │ 10    │\n",
       "│ 2   │ 9     │ 2     │ 1     │ 10    │\n",
       "│ 3   │ 4     │ 1     │ 9     │ 3     │"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = DataFrame(rand(1:10, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we show yet another way to write a `DataFrame` into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a CSV file into the zip file\n",
    "w = ZipFile.Writer(\"x.zip\")\n",
    "\n",
    "f1 = ZipFile.addfile(w, \"x1.csv\")\n",
    "write(f1, sprint(show, \"text/csv\", df1))\n",
    "\n",
    "# write a second CSV file into zip file\n",
    "f2 = ZipFile.addfile(w, \"x2.csv\", method=ZipFile.Deflate)\n",
    "write(f2, sprint(show, \"text/csv\", df2))\n",
    "\n",
    "close(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read the CSV we have written:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = ZipFile.Reader(\"x.zip\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>x1</th><th>x2</th><th>x3</th><th>x4</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>3 rows × 4 columns</p><tr><th>1</th><td>5</td><td>5</td><td>7</td><td>10</td></tr><tr><th>2</th><td>8</td><td>8</td><td>10</td><td>10</td></tr><tr><th>3</th><td>1</td><td>7</td><td>5</td><td>10</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& x1 & x2 & x3 & x4\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 5 & 5 & 7 & 10 \\\\\n",
       "\t2 & 8 & 8 & 10 & 10 \\\\\n",
       "\t3 & 1 & 7 & 5 & 10 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "3×4 DataFrame\n",
       "│ Row │ x1    │ x2    │ x3    │ x4    │\n",
       "│     │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │\n",
       "├─────┼───────┼───────┼───────┼───────┤\n",
       "│ 1   │ 5     │ 5     │ 7     │ 10    │\n",
       "│ 2   │ 8     │ 8     │ 10    │ 10    │\n",
       "│ 3   │ 1     │ 7     │ 5     │ 10    │"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the index index of file called x1.csv\n",
    "index_xcsv = findfirst(x->x.name == \"x1.csv\", z.files)\n",
    "# to read the x1.csv file in the zip file\n",
    "df1_2 = CSV.read(z.files[index_xcsv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_2 == df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>x1</th><th>x2</th><th>x3</th><th>x4</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>3 rows × 4 columns</p><tr><th>1</th><td>10</td><td>9</td><td>6</td><td>10</td></tr><tr><th>2</th><td>9</td><td>2</td><td>1</td><td>10</td></tr><tr><th>3</th><td>4</td><td>1</td><td>9</td><td>3</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& x1 & x2 & x3 & x4\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 10 & 9 & 6 & 10 \\\\\n",
       "\t2 & 9 & 2 & 1 & 10 \\\\\n",
       "\t3 & 4 & 1 & 9 & 3 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "3×4 DataFrame\n",
       "│ Row │ x1    │ x2    │ x3    │ x4    │\n",
       "│     │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │\n",
       "├─────┼───────┼───────┼───────┼───────┤\n",
       "│ 1   │ 10    │ 9     │ 6     │ 10    │\n",
       "│ 2   │ 9     │ 2     │ 1     │ 10    │\n",
       "│ 3   │ 4     │ 1     │ 9     │ 3     │"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the index index of file called x2.csv\n",
    "index_xcsv = findfirst(x->x.name == \"x2.csv\", z.files)\n",
    "# to read the x2.csv file in the zip file\n",
    "df2_2 = CSV.read(z.files[index_xcsv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_2 == df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that once you read a given file from `z` object its stream is all used-up (it is at its end). Therefore to read it again you need to close `z` and open it again.\n",
    "\n",
    "Also do not forget to close the zip file once done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "close(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's clean up. Do not run the next cell unless you are sure that it will not erase your important files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "Base.IOError",
     "evalue": "IOError: unlink: no such file or directory (ENOENT)",
     "output_type": "error",
     "traceback": [
      "IOError: unlink: no such file or directory (ENOENT)",
      "",
      "Stacktrace:",
      " [1] uv_error at ./libuv.jl:97 [inlined]",
      " [2] unlink(::String) at ./file.jl:888",
      " [3] rm(::String; force::Bool, recursive::Bool) at ./file.jl:268",
      " [4] rm at ./file.jl:260 [inlined]",
      " [5] foreach(::typeof(rm), ::Array{String,1}) at ./abstractarray.jl:1919",
      " [6] top-level scope at In[60]:1"
     ]
    }
   ],
   "source": [
    "foreach(rm, [\"x1.csv\", \"x2.csv\", \"x.bin\", \"x.jlso\", \"x.feather\", \"x1.json\", \"x2.json\",\n",
    "             \"bigdf1.csv\", \"bigdf2.csv\", \"bigdf.bin\", \"bigdf.jlso\", \"bigdf.feather\", \"bigdf1.json\", \"bigdf2.json\", \n",
    "             \"df_compress_test.csv.gz\", \"x.zip\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "Base.IOError",
     "evalue": "IOError: unlink: no such file or directory (ENOENT)",
     "output_type": "error",
     "traceback": [
      "IOError: unlink: no such file or directory (ENOENT)",
      "",
      "Stacktrace:",
      " [1] uv_error at ./libuv.jl:97 [inlined]",
      " [2] unlink(::String) at ./file.jl:888",
      " [3] rm(::String; force::Bool, recursive::Bool) at ./file.jl:268",
      " [4] top-level scope at In[61]:1"
     ]
    }
   ],
   "source": [
    "rm(\"bigdf.jdf\", recursive=true)\n",
    "rm(\"x.jdf\", recursive=true)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
